<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Hexo指南</title>
    <link href="/2023/08/04/Hexo%E6%8C%87%E5%8D%97/"/>
    <url>/2023/08/04/Hexo%E6%8C%87%E5%8D%97/</url>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><ol><li>创建新文章<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new &quot;My new post&quot;</span><br></pre></td></tr></table></figure></li><li>启动<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo sever</span><br></pre></td></tr></table></figure></li><li>生成静态文件<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br></pre></td></tr></table></figure></li><li>发布文章<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure></li></ol><h1 id="主题安装"><a href="#主题安装" class="headerlink" title="主题安装"></a>主题安装</h1>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Overleaf指南</title>
    <link href="/2023/08/04/Overleaf%E6%8C%87%E5%8D%97/"/>
    <url>/2023/08/04/Overleaf%E6%8C%87%E5%8D%97/</url>
    
    <content type="html"><![CDATA[<h1 id="Latex"><a href="#Latex" class="headerlink" title="Latex"></a>Latex</h1><p>Latex 是一个用于创建具有专业外观文档的工具，写作者只需要关注文档的内容，Latex 负责将其格式化。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>多机多卡分布式训练</title>
    <link href="/2023/08/03/%E5%A4%9A%E6%9C%BA%E5%A4%9A%E5%8D%A1%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"/>
    <url>/2023/08/03/%E5%A4%9A%E6%9C%BA%E5%A4%9A%E5%8D%A1%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/</url>
    
    <content type="html"><![CDATA[<h1 id="单机多卡分布式训练"><a href="#单机多卡分布式训练" class="headerlink" title="单机多卡分布式训练"></a>单机多卡分布式训练</h1><ol><li>模型并行</li><li>数据并行</li><li>同步更新</li><li>异步更新</li></ol><h2 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h2><h3 id="物理机与虚拟机的关系"><a href="#物理机与虚拟机的关系" class="headerlink" title="物理机与虚拟机的关系"></a>物理机与虚拟机的关系</h3><ol><li><p>内存<br>内存基本上是一个硬限制，物理机的内存肯定是有限的，一台物理机的内存等于其中所有虚拟机的内存之和。</p></li><li><p>CPU</p></li><li><p>目前环境：一台服务器</p></li></ol><h1 id="多极多卡分布式训练"><a href="#多极多卡分布式训练" class="headerlink" title="多极多卡分布式训练"></a>多极多卡分布式训练</h1><ol><li>通信</li><li>nvlink</li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>NLP-tricks</title>
    <link href="/2023/07/11/NLP-tricks/"/>
    <url>/2023/07/11/NLP-tricks/</url>
    
    <content type="html"><![CDATA[<p>对抗训练: <a href="https://zhuanlan.zhihu.com/p/549605526">https://zhuanlan.zhihu.com/p/549605526</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Prompt</title>
    <link href="/2023/07/11/Prompt/"/>
    <url>/2023/07/11/Prompt/</url>
    
    <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/631922240">https://zhuanlan.zhihu.com/p/631922240</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>KCPT实验记录</title>
    <link href="/2023/06/08/KCPT%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%95/"/>
    <url>/2023/06/08/KCPT%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<ol><li>生成16、32、64、128、256shot</li><li>生成positive &#x2F; negative templates</li><li>修改dataset、dataloader</li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>GPT-2</title>
    <link href="/2023/05/24/GPT-2/"/>
    <url>/2023/05/24/GPT-2/</url>
    
    <content type="html"><![CDATA[<h1 id="GPT2介绍"><a href="#GPT2介绍" class="headerlink" title="GPT2介绍"></a>GPT2介绍</h1><p><img src="https://raw.githubusercontent.com/youzhi123/figure_bed/main/imgs/202305240937655.webp" alt="img"></p><p><strong>语言</strong>：英文模型<br><strong>训练数据</strong>：从网络上爬取的40GB超大数据集「WebText」<br><strong>版本和参数</strong>：</p><ul><li>M: 百万</li><li>B: 十亿</li></ul><table><thead><tr><th align="center">Version</th><th align="center">Parameters</th></tr></thead><tbody><tr><td align="center">gpt2</td><td align="center">117M</td></tr><tr><td align="center">gpt2-medium</td><td align="center">345M</td></tr><tr><td align="center">gpt2-large</td><td align="center">762M</td></tr><tr><td align="center">gpt2-extralarge</td><td align="center">1542M&#x2F;1.5B</td></tr></tbody></table><p><img src="https://raw.githubusercontent.com/youzhi123/figure_bed/main/imgs/202305240946482.webp" alt="img"></p><h1 id="GPT2的使用"><a href="#GPT2的使用" class="headerlink" title="GPT2的使用"></a>GPT2的使用</h1><h3 id="GPT2Tokenizer"><a href="#GPT2Tokenizer" class="headerlink" title="GPT2Tokenizer"></a>GPT2Tokenizer</h3><p>GPT2Tokenizer 是以字节为单位的字节对编码Byte Pair Encoding (BPE)，所以中文GPT都是使用BertTokenizer作为分词器</p><h1 id="与Bert的区别"><a href="#与Bert的区别" class="headerlink" title="与Bert的区别"></a>与Bert的区别</h1><p><img src="https://raw.githubusercontent.com/youzhi123/figure_bed/main/imgs/202305240948283.gif" alt="动图"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>大模型评估</title>
    <link href="/2023/05/23/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/"/>
    <url>/2023/05/23/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="计划"><a href="#计划" class="headerlink" title="计划"></a>计划</h1><ol><li>GPT系列模型在基准数据集CLUE和GLUE上的评测</li></ol><ul><li>CLUE和GLUE各种任务的提示构造</li><li>以GPT2(openai)、BERT系列直接出句子的encoder与label进行分类，为基础模型实现大模型评估代码的开发</li></ul><p>规定提示、文本、选项、答案</p><ol start="2"><li>AGIEval基准评测</li></ol><ul><li>ChatGLM（清华）</li><li>Moss（复旦）</li><li>ChatGPT（需要api账号）</li><li>minimax</li></ul><ol start="3"><li>MMCU基准</li></ol><h2 id="如何评估大模型"><a href="#如何评估大模型" class="headerlink" title="如何评估大模型"></a>如何评估大模型</h2><ol><li>在广泛的 NLP 任务上进行评估；</li><li>在高级的 LLM 能力上进行评估，比如算术题、写代码、推理等。</li></ol><h3 id="评估方式"><a href="#评估方式" class="headerlink" title="评估方式"></a>评估方式</h3><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/627812067">https://zhuanlan.zhihu.com/p/627812067</a></p><p>由于大模型参数规模较大，不同的评估方式会涉及到硬件要求（GPU）、显存大小、所需时间以及评估所使用的数据集规模等问题。</p><h4 id="1-fine-tune"><a href="#1-fine-tune" class="headerlink" title="1. fine-tune"></a>1. fine-tune</h4><p>在预训练模型基础上进行全参数微调，以适应下游任务。需要模型全参数训练，因此需要有训练集和测试集，且对训练集规模有要求。</p><h4 id="2-prompt"><a href="#2-prompt" class="headerlink" title="2. prompt"></a>2. prompt</h4><p>通过添加提示来指导模型生成我们想要的答案，在不同的数据场景中提示的构造方式有：</p><h5 id="2-1-few-shot"><a href="#2-1-few-shot" class="headerlink" title="2.1 few-shot"></a>2.1 few-shot</h5><p>只训练提示向量，冻结大模型参数，如p-tuning v2、lora等方法，由于训练的参数少，少样本的训练集即可。</p><h5 id="2-2-zero-shot"><a href="#2-2-zero-shot" class="headerlink" title="2.2 zero-shot"></a>2.2 zero-shot</h5><p>直接将问题和提示文本输入给模型，让他输出答案，但一般都是将答案作为选项一起作为输入，让模型将正确答案选出来。</p><h4 id="3-In-context-Learning-ICL"><a href="#3-In-context-Learning-ICL" class="headerlink" title="3. In-context Learning (ICL)"></a>3. In-context Learning (ICL)</h4><p>上下文学习。不需要训练任何参数，只要给输入添加几个问题和答案作为示例给大模型，让大模型知道后面的问题要以什么样的形式进行回答。</p><h4 id="4-Chain-of-Thought-CoT"><a href="#4-Chain-of-Thought-CoT" class="headerlink" title="4. Chain of Thought (CoT)"></a>4. Chain of Thought (CoT)</h4><p>思维链，一步一步去推导出答案。还未开始调研。。。</p><h3 id="评估数据集"><a href="#评估数据集" class="headerlink" title="评估数据集"></a>评估数据集</h3><h4 id="英文评测基准"><a href="#英文评测基准" class="headerlink" title="英文评测基准"></a>英文评测基准</h4><h5 id="1-GLUE"><a href="#1-GLUE" class="headerlink" title="1. GLUE"></a>1. GLUE</h5><p>dataset：<a href="https://gluebenchmark.com/">https://gluebenchmark.com/</a><br>paper：<a href="https://openreview.net/pdf?id=rJ4km2R5t7">https://openreview.net/pdf?id=rJ4km2R5t7</a><br>code：<a href="https://github.com/nyu-mll/GLUE-baselines">https://github.com/nyu-mll/GLUE-baselines</a><br>Leaderboard：<a href="https://gluebenchmark.com/leaderboard">https://gluebenchmark.com/leaderboard</a></p><p>纽约大学、华盛顿大学等机构创建了一个多任务的自然语言理解基准，主要是NLU任务（9个），包括单句分类和句子对分类。数据形式简单，不具体介绍每一个数据集了。</p><h5 id="2-SuperGLUE"><a href="#2-SuperGLUE" class="headerlink" title="2. SuperGLUE"></a>2. SuperGLUE</h5><p>参考链接1：<a href="https://zhuanlan.zhihu.com/p/64114978">https://zhuanlan.zhihu.com/p/64114978</a><br>参考链接2：<a href="https://zhuanlan.zhihu.com/p/623534998">https://zhuanlan.zhihu.com/p/623534998</a><br>dataset：<a href="https://super.gluebenchmark.com/">https://super.gluebenchmark.com/</a><br>paper：<a href="https://w4ngatang.github.io/static/papers/superglue.pdf">https://w4ngatang.github.io/static/papers/superglue.pdf</a><br>code：<a href="https://github.com/nyu-mll/jiant">https://github.com/nyu-mll/jiant</a><br>Leaderboard：<a href="https://super.gluebenchmark.com/leaderboard">https://super.gluebenchmark.com/leaderboard</a></p><p>2018年Bert的出现，在三个 GLUE 任务（QNLI、 MRPC 和 QQP）上，最佳的模型已经超过了人类基准，为此纽约大学、Facebook 人工智能研究所、华盛顿大学和剑桥大学的多名研究者联合整理发布了SuperGLUE。</p><p><img src="https://raw.githubusercontent.com/youzhi123/figure_bed/main/imgs/202305251039911.webp" alt="img"></p><p>SuperGLUE同样是NLU任务（7个），其中保留了两项 GLUE 任务，另外又加入了五个难度更大的新任务。数据形式具体介绍如下：</p><h6 id="1-CB"><a href="#1-CB" class="headerlink" title="1. CB"></a>1. CB</h6><p>三类的文本蕴含任务，每个样本都包含一个前提（premise）和对应的假设（hypothesis）。</p><p><img src="https://raw.githubusercontent.com/youzhi123/figure_bed/main/imgs/202305251045781.webp" alt="img"></p><h6 id="2-COPA"><a href="#2-COPA" class="headerlink" title="2. COPA"></a>2. COPA</h6><p>因果推理任务，每个样本包括一个前提句子和两个可能（原因或结果）的可选项。</p><p><img src="https://raw.githubusercontent.com/youzhi123/figure_bed/main/imgs/202305251047288.webp" alt="img"></p><h6 id="3-ReCoRD"><a href="#3-ReCoRD" class="headerlink" title="3. ReCoRD"></a>3. ReCoRD</h6><p>阅读理解任务，给定一个段落和一组问题，要求从段落中标记出能够回答问题的部分。</p><p><img src="https://raw.githubusercontent.com/youzhi123/figure_bed/main/imgs/202305251133833.png" alt="image-20230525113325820"></p><h6 id="4-MultiRC"><a href="#4-MultiRC" class="headerlink" title="4. MultiRC"></a>4. MultiRC</h6><p>多项选择任务，每个样本都包含一个上下文段落、一个有关该段落的问题和一个该问题的可能答案的列表。</p><p><img src="https://raw.githubusercontent.com/youzhi123/figure_bed/main/imgs/202305251117617.webp" alt="img"></p><h6 id="5-RTE"><a href="#5-RTE" class="headerlink" title="5. RTE"></a>5. RTE</h6><p>文本蕴涵任务，预测给定的前提句子是否蕴涵给定的假设句子，也称为自然语言推理任务。</p><p><img src="https://raw.githubusercontent.com/youzhi123/figure_bed/main/imgs/202305251119670.webp" alt="img"></p><h6 id="6-WiC"><a href="#6-WiC" class="headerlink" title="6. WiC"></a>6. WiC</h6><p>词义消岐任务，该任务被设定成了在句子对上的二元分类问题。给定两个句子和一个出现在这两个句子中的多义词（歧义词），任务目标是决定该词在这两个句子中是否含义相同。</p><p><img src="https://raw.githubusercontent.com/youzhi123/figure_bed/main/imgs/202305251120883.webp" alt="img"></p><h6 id="7-WSC"><a href="#7-WSC" class="headerlink" title="7. WSC"></a>7. WSC</h6><p>阅读理解任务，每个样本包括一个带有一个代词的句子，并从一个选项列表中选择该代词所代指的目标，被设定成了二元分类问题。</p><p><img src="https://raw.githubusercontent.com/youzhi123/figure_bed/main/imgs/202305251123554.webp" alt="img"></p><h5 id="3-others"><a href="#3-others" class="headerlink" title="3. others"></a>3. others</h5><ol><li>MMLU基准（Hendrycks等人，2021a）提供了从真实世界的考试和书籍中收集的多领域和多任务评价。</li><li>BIG-bench基准（Srivastava等人，2022年）包括204个不同的任务，其中一些任务被认为超出了当前LLM的能力。</li></ol><ul><li>HELM基准（Liang等人，2022年）汇总了42个不同的任务，用从准确性到鲁棒性的7个指标来评估LLMs。</li></ul><h2 id="大模型及评估结果"><a href="#大模型及评估结果" class="headerlink" title="大模型及评估结果"></a>大模型及评估结果</h2><h3 id="中文大模型"><a href="#中文大模型" class="headerlink" title="中文大模型"></a>中文大模型</h3><h4 id="1-ChatGLM-6B"><a href="#1-ChatGLM-6B" class="headerlink" title="1. ChatGLM-6B"></a>1. ChatGLM-6B</h4><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/630134021">https://zhuanlan.zhihu.com/p/630134021</a><br>模型文件：<a href="https://huggingface.co/THUDM/chatglm-6b">https://huggingface.co/THUDM/chatglm-6b</a><br>code：<a href="https://github.com/THUDM/ChatGLM-6B">https://github.com/THUDM/ChatGLM-6B</a><br>blog：<a href="https://chatglm.cn/blog">https://chatglm.cn/blog</a><br>paper：<a href="https://arxiv.org/pdf/2103.10360.pdf">https://arxiv.org/pdf/2103.10360.pdf</a></p><p>ChatGLM-6B 出自清华，是一个开源的、支持中英双语的对话语言模型，基于 GLM 架构，具有 62 亿参数。ChatGLM-6B 使用了和 ChatGPT 相似的技术，针对中文问答和对话进行了优化。使用约 1T 标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持。</p><p>为了方便开发者针对自己的下游场景定制模型，其开源项目中提供了基于 P-Tuning v2 的高效参数微调代码，INT4 量化级别下最低需要 7GB 显存即可启动微调。</p><p>在另一个大模型能力评估项目 <a href="https://github.com/SJTU-LIT/ceval">C-Eval</a> 中，其提供了ChatGLM-6B 的 In-context Learning 方式的评估代码，我们后面对 ChatGLM-6B 的评估基于此,<a href="https://www.cluebenchmarks.com/">FewCLUE</a> 。</p><h4 id="2-MOSS"><a href="#2-MOSS" class="headerlink" title="2. MOSS"></a>2. MOSS</h4><h4 id="3-GPT2-Chinese"><a href="#3-GPT2-Chinese" class="headerlink" title="3. GPT2-Chinese"></a>3. GPT2-Chinese</h4><h3 id="英文大模型"><a href="#英文大模型" class="headerlink" title="英文大模型"></a>英文大模型</h3><h3 id="公开的评估结果"><a href="#公开的评估结果" class="headerlink" title="公开的评估结果"></a>公开的评估结果</h3><h3 id="我们的评估结果"><a href="#我们的评估结果" class="headerlink" title="我们的评估结果"></a>我们的评估结果</h3><p><a href="https://github.com/SJTU-LIT/ceval">https://github.com/SJTU-LIT/ceval</a></p><p>SuperCLUE的评测任务究竟范围如何，到现在为止也没有公布出来</p><h3 id="中文评测基准："><a href="#中文评测基准：" class="headerlink" title="中文评测基准："></a>中文评测基准：</h3><ul><li>CLUE基准（Xu等人，2020）是第一个大规模的中文NLU基准，现在仍然是使用最广泛的中文基准。</li><li>CUGE</li><li>AGIEval基准（Zhong等人，2023）包含了来自中国高考、中国律师资格考试和中国公务员考试的数据。</li><li>MMCU基准（Zeng，2023）包括来自医学、法律、心理学和教育等四大领域的测试，这些数据也是从中国高考、资格考试以及大学考试中收集的。</li></ul><h2 id="1-GLUE-1"><a href="#1-GLUE-1" class="headerlink" title="1. GLUE"></a>1. GLUE</h2><h2 id="2-MMLU"><a href="#2-MMLU" class="headerlink" title="2. MMLU"></a>2. MMLU</h2><h2 id="3-BIG-bench"><a href="#3-BIG-bench" class="headerlink" title="3. BIG-bench"></a>3. BIG-bench</h2><h2 id="4-HELM"><a href="#4-HELM" class="headerlink" title="4. HELM"></a>4. HELM</h2><h1 id="中文评测基准"><a href="#中文评测基准" class="headerlink" title="中文评测基准"></a>中文评测基准</h1><h2 id="CLUE"><a href="#CLUE" class="headerlink" title="CLUE"></a>CLUE</h2><p>github: <a href="https://github.com/CLUEbenchmark/SuperCLUE">https://github.com/CLUEbenchmark/SuperCLUE</a></p><h2 id="AGIEval"><a href="#AGIEval" class="headerlink" title="AGIEval"></a>AGIEval</h2><p>github: <a href="https://github.com/SJTU-LIT/ceval">https://github.com/SJTU-LIT/ceval</a><br>官网: <a href="https://cevalbenchmark.com/">https://cevalbenchmark.com/</a></p><h2 id="MMCU"><a href="#MMCU" class="headerlink" title="MMCU"></a>MMCU</h2><p>github: <a href="https://github.com/Felixgithub2017/MMCU">https://github.com/Felixgithub2017/MMCU</a></p><table><thead><tr><th align="center">Corpus</th><th align="center">example</th><th align="center">description</th></tr></thead><tbody><tr><td align="center">CB</td><td align="center">8.5k</td><td align="center">1k</td></tr><tr><td align="center">SST-2</td><td align="center">67k</td><td align="center"></td></tr></tbody></table>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>GLUE基准数据集</title>
    <link href="/2023/05/22/GLUE%E5%9F%BA%E5%87%86%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    <url>/2023/05/22/GLUE%E5%9F%BA%E5%87%86%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>自然语言处理（NLP）主要包括自然语言理解（NLU）和自然语言生成（NLG）。为了让NLU任务发挥最大的作用，来自纽约大学、华盛顿大学等机构创建了一个多任务的自然语言理解基准和分析平台，也就是GLUE（General Language Understanding Evaluation）。</p><p>GLUE包含九项NLU任务，语言均为英语。GLUE九项任务涉及到自然语言推断、文本蕴含、情感分析、语义相似等多个任务。</p><p>GLUE的论文为：GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding</p><p>GLUE的官网为：<a href="https://gluebenchmark.com/">https://gluebenchmark.com/</a></p><h1 id="任务介绍"><a href="#任务介绍" class="headerlink" title="任务介绍"></a>任务介绍</h1><p>GLUE共有九个任务，分别是CoLA、SST-2、MRPC、STS-B、QQP、MNLI、QNLI、RTE、WNLI，其中SST-B是一个回归任务，其他任务都是单句分类或句子对分类。MNLI有3个类别，其他分类任务都只有两个类别。</p><p>任务分为三类，分别是单句任务，相似性&#x2F;释义任务和自然语言推理。</p><p>| Corpus | |Train| | |Dev| | |Test| | Task | Metriics | Domain |<br>| :—– | :—–: | :—: | :—-: | :–: | :——: | :—-: |<br>| CoLA   | 8.5k    | 1k    | 1k     |acceptability(语言可接受性语料库)| MCC, Matthews correlation coefficient | |<br>| SST-2  | 67k     |  |sentiment(情感分析)| | </p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Pythia</title>
    <link href="/2023/05/13/Pythia/"/>
    <url>/2023/05/13/Pythia/</url>
    
    <content type="html"><![CDATA[<h1 id="Pythia"><a href="#Pythia" class="headerlink" title="Pythia"></a>Pythia</h1><p>文献 Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling</p><p>大型语言模型（LLMs）在训练过程中是如何发展和演变的？这些模式是如何随着模型的扩大而变化的？</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>对比学习</title>
    <link href="/2023/05/12/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/05/12/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<p>对比学习</p><p>最简单的正负样本数据构造方式：<br>一个batch有N个样本，对每个anchor样本构造一个正样本，就变成了2N个样本，其中有1个anchor样本，1个正样本，2N-2个负样本</p><p>对比学习Loss</p><h1 id="SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings"><a href="#SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings" class="headerlink" title="SimCSE: Simple Contrastive Learning of Sentence Embeddings"></a>SimCSE: Simple Contrastive Learning of Sentence Embeddings</h1><h1 id="DIFFERENTIABLE-PROMPT-MAKES-PRE-TRAINED-LANGUAGE-MODELS-BETTER-FEW-SHOT-LEARNERS"><a href="#DIFFERENTIABLE-PROMPT-MAKES-PRE-TRAINED-LANGUAGE-MODELS-BETTER-FEW-SHOT-LEARNERS" class="headerlink" title="DIFFERENTIABLE PROMPT MAKES PRE-TRAINED LANGUAGE MODELS BETTER FEW-SHOT LEARNERS"></a>DIFFERENTIABLE PROMPT MAKES PRE-TRAINED LANGUAGE MODELS BETTER FEW-SHOT LEARNERS</h1><h1 id="Differentiable-Prompt-Makes-Pre-trained-Language-Model-Better-Few-shot-Learners"><a href="#Differentiable-Prompt-Makes-Pre-trained-Language-Model-Better-Few-shot-Learners" class="headerlink" title="Differentiable Prompt Makes Pre-trained Language Model Better Few-shot Learners"></a>Differentiable Prompt Makes Pre-trained Language Model Better Few-shot Learners</h1><p>可微分的提示使预训练的语言模型更好地学习</p><p>Abstract<br>大规模预训练语言模型对自然语言处理做出了重大的贡献通过在小样本上表现出非凡的能力。然而，它们的有效性主要取决于模型参数的规模和提示的设计，这阻碍了它们在大多数实际应用中的实现。本研究提出了一种新颖的可插入、可扩展且高效的方法，名为 DifferentiAble pRompT (DART)，它可以将小型语言模型转换为更好的小样本学习器。这种方法背后的主要原理是将潜在的自然语言处理任务重新表述为预训练语言模型的任务，并通过反向传播对提示模板和目标标签进行差异化优化。具体来说，所提出的方法为：（i）插入任何预先训练的语言模型； (ii) 扩展到广泛的分类任务。对标准 NLP 任务的综合评估表明，所提出的方法实现了更好的小样本性能。</p><p>代理任务</p><ol><li>个体判别</li><li>预测未来</li><li>多视角</li><li>多模态</li></ol><p>目标函数</p><ol><li>NCE</li><li>InfoNCE</li><li>NCE的其他变体</li></ol><p>编码器</p><ol><li>一个编码器</li><li>一个编码器 和 MemeryBank</li><li>一个编码器 和 一个自回归模型</li><li>两个甚至多个编码器</li></ol><h1 id="MoCo"><a href="#MoCo" class="headerlink" title="MoCo"></a>MoCo</h1><h1 id="InstDisc"><a href="#InstDisc" class="headerlink" title="InstDisc"></a>InstDisc</h1><h1 id="SimCLR"><a href="#SimCLR" class="headerlink" title="SimCLR"></a>SimCLR</h1><h1 id="CPC-CMC"><a href="#CPC-CMC" class="headerlink" title="CPC CMC"></a>CPC CMC</h1><h1 id=""><a href="#" class="headerlink" title=""></a></h1><h1 id="不用负样本"><a href="#不用负样本" class="headerlink" title="不用负样本"></a>不用负样本</h1><h1 id="SimSiam"><a href="#SimSiam" class="headerlink" title="SimSiam"></a>SimSiam</h1><h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>开发工具-docker</title>
    <link href="/2023/05/07/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7-docker/"/>
    <url>/2023/05/07/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7-docker/</url>
    
    <content type="html"><![CDATA[<p>添加镜像源</p><ol><li>创建或修改<code>/etc/docker/daemon.json</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;registry-mirrors&quot;: [</span><br><span class="line">        &quot;http://hub-mirror.c.163.com&quot;,</span><br><span class="line">        &quot;https://docker.mirrors.ustc.edu.cn&quot;,</span><br><span class="line">        &quot;https://registry.docker-cn.com&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>重启docker<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service docker restart</span><br></pre></td></tr></table></figure></li><li>查看dokcer信息<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker info</span><br></pre></td></tr></table></figure></li></ol><p>拉取镜像</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull &lt;镜像名/镜像id&gt;</span><br></pre></td></tr></table></figure><p>创建容器</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name &lt;xx&gt; -p &lt;1234&gt;:&lt;1234&gt; -v /home/workspace:/home/workspace --gpus all --shm-size=&#x27;16g&#x27; &lt;image_id&gt; /bin/bash</span><br></pre></td></tr></table></figure><p>vscode设置ssh远程连接</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">在本地生成ssh密钥: ssh-keygen -t rsa</span><br><span class="line">将公钥 id_rsa.pub 复制到远程服务器的 .ssh/ 文件夹下</span><br><span class="line">在服务器的 .ssh/文件夹中执行：cat id_rsa.pub &gt;&gt; authorized_keys</span><br><span class="line">密钥形式登录的原理是：利用密钥生成器制作一对密钥——一只公钥和一只私钥。将公钥添加到服务器的某个账户上，然后在客户端利用私钥即可完成认证并登录。这样一来，没有私钥，任何人都无法通过 SSH 暴力破解你的密码来远程登录到系统。此外，如果将公钥复制到其他账户甚至主机，利用私钥也可以登录。</span><br><span class="line"></span><br><span class="line">vscode中在本地安装插件</span><br><span class="line">remote-ssh</span><br><span class="line">remote-development</span><br></pre></td></tr></table></figure><p>设置pip源</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mkdir ~/.pip &amp;&amp; touch ~/.pip/pip.conf</span><br><span class="line"></span><br><span class="line">[global]</span><br><span class="line">index-url=https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">extra-index-url=http://mirrors.aliyun.com/pypi/simple</span><br><span class="line">[install]</span><br><span class="line">trusted-host=pypi.tuna.tsinghua.edu.cn</span><br><span class="line">extra-trusted-host=mirrors.aliyun.com</span><br></pre></td></tr></table></figure><p>安装tf1.15-cuda11-cudnn8</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda create --name tf115 python=3.8</span><br><span class="line">pip install --upgrade pip</span><br><span class="line">pip install nvidia-pyindex</span><br><span class="line">pip install nvidia-tensorflow[horovod]</span><br><span class="line">pip install nvidia-tensorboard==1.15</span><br></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>开发工具-vscode</title>
    <link href="/2023/05/07/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7-vscode/"/>
    <url>/2023/05/07/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7-vscode/</url>
    
    <content type="html"><![CDATA[<p>现在251和235的root登陆密码都改成了kcSmRpX9sR*&amp;8szu</p><p>两个服务器直接传文件：<br>scp -r t5-base&#x2F; <a href="mailto:&#x72;&#x6f;&#x6f;&#116;&#x40;&#49;&#x39;&#x32;&#x2e;&#x31;&#x36;&#x38;&#46;&#56;&#x33;&#x2e;&#50;&#x35;&#x31;">&#x72;&#x6f;&#x6f;&#116;&#x40;&#49;&#x39;&#x32;&#x2e;&#x31;&#x36;&#x38;&#46;&#56;&#x33;&#x2e;&#50;&#x35;&#x31;</a>:&#x2F;home&#x2F;huangyouzhi&#x2F;PLMs&#x2F;English&#x2F;<br><img src="https://raw.githubusercontent.com/youzhi123/figure_bed/main/imgs/202307121726251.png" alt="image-20230712172602633"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>hexo日常使用记录</title>
    <link href="/2023/04/29/hexo%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/"/>
    <url>/2023/04/29/hexo%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<h1 id="主题相关操作"><a href="#主题相关操作" class="headerlink" title="主题相关操作"></a>主题相关操作</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 下载主题</span><br><span class="line">cd themes</span><br><span class="line">git clone &lt;主题地址&gt;</span><br><span class="line"></span><br><span class="line"># 安装渲染器</span><br><span class="line">npm install hexo-renderer-pug hexo-renderer-stylus</span><br><span class="line"></span><br><span class="line"># 配置使用主题, 修改_config.yml</span><br><span class="line">theme: hexo-theme-butterfly</span><br></pre></td></tr></table></figure><h1 id="修改首页显示"><a href="#修改首页显示" class="headerlink" title="修改首页显示"></a>修改首页显示</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><h1 id="新建博文"><a href="#新建博文" class="headerlink" title="新建博文"></a>新建博文</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new &quot;博文名&quot; </span><br></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/04/14/hello-world/"/>
    <url>/2023/04/14/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
